{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "# print(GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "llm = ChatGroq(model_name = 'Gemma2-9b-It')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple AI Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     question = input(\"Enter your question. If you want to quit write quit\")\n",
    "#     if question != \"quit\":\n",
    "#         print(llm.invoke(question).content)\n",
    "#     else:\n",
    "#         print(\"Goodbye Take care of Yourelf\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "langgraph-pre-requisites\n"
     ]
    }
   ],
   "source": [
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "print(LANGSMITH_API_KEY)\n",
    "\n",
    "LANGCHAIN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "print(LANGCHAIN_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\" : {\"session_id\":\"firstchat\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_memory = RunnableWithMessageHistory(llm,session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Akash! ðŸ‘‹\\n\\nIt's nice to meet you. What can I do for you today? ðŸ˜Š  \\n\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke((\"Hi! I am Akash\"),config = config).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You told me your name is Akash.  \n",
      "\n",
      "Is there something else you'd like to know or talk about?  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_with_memory.invoke((\"What is my name?\"),config = config).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Akash! ðŸ‘‹  How can I help you today? ðŸ˜Š\n",
      "Your name is Akash.  \n",
      "\n",
      "Is there anything else I can help you with? ðŸ˜Š \n",
      "\n",
      "Okay, here's some information about AI:\n",
      "\n",
      "**What is AI?**\n",
      "\n",
      "AI stands for Artificial Intelligence. It's a broad field of computer science that aims to create machines capable of performing tasks that typically require human intelligence.\n",
      "\n",
      "**What can AI do?**\n",
      "\n",
      "AI can do a wide range of things, including:\n",
      "\n",
      "* **Learn from data:** AI systems can be trained on large datasets to recognize patterns, make predictions, and improve their performance over time.\n",
      "* **Understand and respond to natural language:** This allows for things like chatbots, virtual assistants, and language translation.\n",
      "* **Solve problems:** AI can be used to find solutions to complex problems in areas like healthcare, finance, and logistics.\n",
      "* **Create art and content:** AI can generate music, write stories, and even create images.\n",
      "\n",
      "**Types of AI:**\n",
      "\n",
      "* **Narrow or Weak AI:**  This type of AI is designed to perform a specific task, like playing chess or recommending products. Most AI we encounter today falls under this category.\n",
      "* **General or Strong AI:**  This is a hypothetical type of AI that would have human-level intelligence and be able to perform any intellectual task that a human can.\n",
      "* **Super AI:**  This is a hypothetical type of AI that would surpass human intelligence in all aspects.\n",
      "\n",
      "**Examples of AI in action:**\n",
      "\n",
      "* **Self-driving cars**\n",
      "* **Personalized recommendations on Netflix or Amazon**\n",
      "* **Spam filters in your email**\n",
      "* **Voice assistants like Siri or Alexa**\n",
      "* **Medical diagnosis tools**\n",
      "\n",
      "**Ethical considerations:**\n",
      "\n",
      "The development and deployment of AI raise important ethical questions, such as:\n",
      "\n",
      "* **Bias:** AI systems can inherit and amplify biases present in the data they are trained on.\n",
      "* **Job displacement:** AI automation may lead to job losses in certain sectors.\n",
      "* **Privacy:** AI can be used to collect and analyze vast amounts of personal data.\n",
      "* **Accountability:** It can be difficult to determine who is responsible when an AI system makes a harmful decision.\n",
      "\n",
      "\n",
      "Let me know if you have any other questions about AI!\n",
      "\n",
      "Goodbye Take care of Yourelf\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question = input(\"Enter your question. If you want to quit write quit\")\n",
    "    if question != \"quit\":\n",
    "        print(model_with_memory.invoke((question),config = config).content)\n",
    "    else:\n",
    "        print(\"Goodbye Take care of Yourelf\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
